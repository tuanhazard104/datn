# Copyright 2020 MONAI Consortium
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#     http://www.apache.org/licenses/LICENSE-2.0
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import time
from argparse import ArgumentParser

import numpy as np
import torch
from data_utils import get_filenames, load_data_and_mask
from torchgpipe import GPipe
from torchgpipe.balance import balance_by_size
from unet_pipe import UNetPipe, flatten_sequential

from monai.data import Dataset, list_data_collate
from monai.losses import DiceLoss, FocalLoss
from monai.metrics import compute_meandice
from monai.transforms import AddChannelDict, Compose, Rand3DElasticd, RandCropByPosNegLabeld, SpatialPadd
from monai.utils import first

N_CLASSES = 10
TRAIN_PATH = "./data/HaN/train/"  # training data folder
VAL_PATH = "./data/HaN/test/"  # validation data folder

torch.backends.cudnn.enabled = True


class ImageLabelDataset:
    """
    Load image and multi-class labels based on the predefined folder structure.
    """

    def __init__(self, path, n_class=10):
        self.path = path
        self.data = sorted(os.listdir(path))
        self.n_class = n_class

    def __getitem__(self, index):
        data = os.path.join(self.path, self.data[index])
        train_data, train_masks_data = get_filenames(data)
        data = load_data_and_mask(train_data, train_masks_data)  # read into a data dict
        # loading image
        data["image"] = data["image"].astype(np.float32)  # shape (H W D)
        # loading labels
        class_shape = (1,) + data["image"].shape
        mask0 = np.zeros(class_shape)
        mask_list = []
        flagvect = np.ones((self.n_class,), np.float32)
        for i, mask in enumerate(data["label"]):
            if mask is None:
                mask = np.zeros(class_shape)
                flagvect[0] = 0
                flagvect[i + 1] = 0
            mask0 = np.logical_or(mask0, mask)
            mask_list.append(mask.reshape(class_shape))
        mask0 = 1 - mask0
        data["label"] = np.concatenate([mask0] + mask_list, axis=0).astype(np.uint8)  # shape (C H W D)
        # setting flags
        # flagvec is a boolean indicator for complete annotation
        data["with_complete_groundtruth"] = flagvect
        return data

    def __len__(self):
        return len(self.data)


def train(n_feat, crop_size, bs, ep, optimizer="rmsprop", lr=5e-4, pretrain=None):
    model_name = f"./HaN_{n_feat}_{bs}_{ep}_{crop_size}_{lr}_"
    print(f"save the best model as '{model_name}' during training.")

    crop_size = [int(cz) for cz in crop_size.split(",")]
    print(f"input image crop_size: {crop_size}")

    # starting training set loader
    train_images = ImageLabelDataset(path=TRAIN_PATH, n_class=N_CLASSES)
    if np.any([cz == -1 for cz in crop_size]):  # using full image
        train_transform = Compose(
            [
                AddChannelDict(keys="image"),
                Rand3DElasticd(
                    keys=("image", "label"),
                    spatial_size=crop_size,
                    sigma_range=(10, 50),  # 30
                    magnitude_range=(600, 1200),  # 1000
                    prob=0.8,
                    rotate_range=(np.pi / 12, np.pi / 12, np.pi / 12),
                    shear_range=(np.pi / 18, np.pi / 18, np.pi / 18),
                    translate_range=tuple(sz * 0.05 for sz in crop_size),
                    scale_range=(0.2, 0.2, 0.2),
                    mode=("bilinear", "nearest"),
                    padding_mode=("border", "zeros"),
                ),
            ]
        )
        train_dataset = Dataset(train_images, transform=train_transform)
        # when bs > 1, the loader assumes that the full image sizes are the
        # same across the dataset
        train_dataloader = torch.utils.data.DataLoader(train_dataset, num_workers=4, batch_size=bs, shuffle=True)
    else:
        # draw balanced foreground/background window samples according to the
        # ground truth label
        train_transform = Compose(
            [
                AddChannelDict(keys="image"),
                SpatialPadd(keys=("image", "label"), spatial_size=crop_size),
                # ensure image size >= crop_size
                RandCropByPosNegLabeld(
                    keys=("image", "label"), label_key="label", spatial_size=crop_size, num_samples=bs
                ),
                Rand3DElasticd(
                    keys=("image", "label"),
                    spatial_size=crop_size,
                    sigma_range=(10, 50),  # 30
                    magnitude_range=(600, 1200),  # 1000
                    prob=0.8,
                    rotate_range=(np.pi / 12, np.pi / 12, np.pi / 12),
                    shear_range=(np.pi / 18, np.pi / 18, np.pi / 18),
                    translate_range=tuple(sz * 0.05 for sz in crop_size),
                    scale_range=(0.2, 0.2, 0.2),
                    mode=("bilinear", "nearest"),
                    padding_mode=("border", "zeros"),
                ),
            ]
        )
        # each dataset item is a list of windows
        train_dataset = Dataset(train_images, transform=train_transform)
        train_dataloader = torch.utils.data.DataLoader(  # stack each dataset item into a single tensor
            train_dataset, num_workers=4, batch_size=1, shuffle=True, collate_fn=list_data_collate
        )
    first_sample = first(train_dataloader)
    print(first_sample["image"].shape)

    # starting validation set loader
    val_transform = Compose([AddChannelDict(keys="image")])
    val_dataset = Dataset(ImageLabelDataset(VAL_PATH, n_class=N_CLASSES), transform=val_transform)
    val_dataloader = torch.utils.data.DataLoader(val_dataset, num_workers=1, batch_size=1)
    print(val_dataset[0]["image"].shape)
    print(f"training images: {len(train_dataloader)}, validation images: {len(val_dataloader)}")

    model = UNetPipe(spatial_dims=3, in_channels=1, out_channels=N_CLASSES, n_feat=n_feat)
    model = flatten_sequential(model)
    lossweight = torch.from_numpy(np.array([2.22, 1.31, 1.99, 1.13, 1.93, 1.93, 1.0, 1.0, 1.90, 1.98], np.float32))

    if optimizer.lower() == "rmsprop":
        optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)  # lr = 5e-4
    elif optimizer.lower() == "momentum":
        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)  # lr = 1e-4 for finetuning
    else:
        raise ValueError(f"Unknown optimizer type {optimizer}. (options are 'rmsprop' and 'momentum').")

    # config GPipe
    x = first_sample["image"].float()
    x = torch.autograd.Variable(x.cuda())
    partitions = torch.cuda.device_count()
    print(f"partition: {partitions}, input: {x.size()}")
    balance = balance_by_size(partitions, model, x)
    model = GPipe(model, balance, chunks=4, checkpoint="always")

    # config loss functions
    dice_loss_func = DiceLoss(softmax=True, reduction="none")
    # use the same pipeline and loss in
    # AnatomyNet: Deep learning for fast and fully automated whole‚Äêvolume segmentation of head and neck anatomy,
    # Medical Physics, 2018.
    focal_loss_func = FocalLoss(reduction="none")

    if pretrain:
        print(f"loading from {pretrain}.")
        pretrained_dict = torch.load(pretrain)["weight"]
        model_dict = model.state_dict()
        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}
        model_dict.update(pretrained_dict)
        model.load_state_dict(pretrained_dict)

    b_time = time.time()
    best_val_loss = [0] * (N_CLASSES - 1)  # foreground
    for epoch in range(ep):
        model.train()
        trainloss = 0
        for b_idx, data_dict in enumerate(train_dataloader):
            x_train = data_dict["image"]
            y_train = data_dict["label"]
            flagvec = data_dict["with_complete_groundtruth"]

            x_train = torch.autograd.Variable(x_train.cuda())
            y_train = torch.autograd.Variable(y_train.cuda().float())
            optimizer.zero_grad()
            o = model(x_train).to(0, non_blocking=True).float()

            loss = (dice_loss_func(o, y_train.to(o)) * flagvec.to(o) * lossweight.to(o)).mean()
            loss += 0.5 * (focal_loss_func(o, y_train.to(o)) * flagvec.to(o) * lossweight.to(o)).mean()
            loss.backward()
            optimizer.step()
            trainloss += loss.item()

            if b_idx % 20 == 0:
                print(f"Train Epoch: {epoch} [{b_idx}/{len(train_dataloader)}] \tLoss: {loss.item()}")
        print(f"epoch {epoch} TRAIN loss {trainloss / len(train_dataloader)}")

        if epoch % 10 == 0:
            model.eval()
            # check validation dice
            val_loss = [0] * (N_CLASSES - 1)
            n_val = [0] * (N_CLASSES - 1)
            for data_dict in val_dataloader:
                x_val = data_dict["image"]
                y_val = data_dict["label"]
                with torch.no_grad():
                    x_val = torch.autograd.Variable(x_val.cuda())
                o = model(x_val).to(0, non_blocking=True)
                loss = compute_meandice(o, y_val.to(o), mutually_exclusive=True, include_background=False)
                val_loss = [l.item() + tl if l == l else tl for l, tl in zip(loss[0], val_loss)]
                n_val = [n + 1 if l == l else n for l, n in zip(loss[0], n_val)]
            val_loss = [l / n for l, n in zip(val_loss, n_val)]
            print("validation scores %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f" % tuple(val_loss))
            for c in range(1, 10):
                if best_val_loss[c - 1] < val_loss[c - 1]:
                    best_val_loss[c - 1] = val_loss[c - 1]
                    state = {"epoch": epoch, "weight": model.state_dict(), "score_" + str(c): best_val_loss[c - 1]}
                    torch.save(state, f"{model_name}" + str(c))
            print("best validation scores %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f, %.4f" % tuple(best_val_loss))

    print("total time", time.time() - b_time)


if __name__ == "__main__":
    parser = ArgumentParser()
    parser.add_argument("--n_feat", type=int, default=32, dest="n_feat")
    parser.add_argument("--crop_size", type=str, default="-1,-1,-1", dest="crop_size")
    parser.add_argument("--bs", type=int, default=1, dest="bs")  # batch size
    parser.add_argument("--ep", type=int, default=150, dest="ep")  # number of epochs
    parser.add_argument("--lr", type=float, default=5e-4, dest="lr")  # learning rate
    parser.add_argument("--optimizer", type=str, default="rmsprop", dest="optimizer")  # type of optimizer
    parser.add_argument("--pretrain", type=str, default=None, dest="pretrain")
    args = parser.parse_args()

    input_dict = vars(args)
    print(input_dict)
    train(**input_dict)
