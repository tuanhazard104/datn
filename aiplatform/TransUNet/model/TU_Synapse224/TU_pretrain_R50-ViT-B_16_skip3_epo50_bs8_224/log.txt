[10:09:04.599] Namespace(base_lr=0.01, batch_size=8, dataset='Synapse', deterministic=1, exp='TU_Synapse224', img_size=224, is_pretrain=True, list_dir='./lists/lists_Synapse', max_epochs=50, max_iterations=30000, n_gpu=1, n_skip=3, num_classes=9, root_path='../data/Synapse/train_npz', seed=1234, vit_name='R50-ViT-B_16', vit_patches_size=16)
[10:09:04.603] 277 iterations per epoch. 13850 max iterations 
[10:09:05.490] iteration 1 : loss : 1.466684, loss_ce: 2.015675
[10:09:05.802] iteration 2 : loss : 1.423045, loss_ce: 1.919130
[10:09:06.112] iteration 3 : loss : 1.340470, loss_ce: 1.751458
[10:09:06.423] iteration 4 : loss : 1.232435, loss_ce: 1.548258
[10:09:06.731] iteration 5 : loss : 1.112509, loss_ce: 1.316419
[10:09:07.039] iteration 6 : loss : 0.981451, loss_ce: 1.053753
[10:09:07.349] iteration 7 : loss : 0.874686, loss_ce: 0.884624
[10:09:07.658] iteration 8 : loss : 0.772534, loss_ce: 0.676169
[10:09:07.970] iteration 9 : loss : 0.691596, loss_ce: 0.522540
[10:09:08.279] iteration 10 : loss : 0.626087, loss_ce: 0.386253
[10:09:08.589] iteration 11 : loss : 0.622503, loss_ce: 0.395660
[10:09:08.898] iteration 12 : loss : 0.547007, loss_ce: 0.225101
[10:09:09.208] iteration 13 : loss : 0.611621, loss_ce: 0.363489
[10:09:09.517] iteration 14 : loss : 0.570980, loss_ce: 0.289684
[10:09:09.828] iteration 15 : loss : 0.552240, loss_ce: 0.249148
[10:09:10.135] iteration 16 : loss : 0.545640, loss_ce: 0.238461
[10:09:10.443] iteration 17 : loss : 0.548166, loss_ce: 0.236701
[10:09:10.754] iteration 18 : loss : 0.493283, loss_ce: 0.141758
[10:09:11.065] iteration 19 : loss : 0.504220, loss_ce: 0.144772
[10:09:11.378] iteration 20 : loss : 0.552307, loss_ce: 0.267769
[10:09:11.718] iteration 21 : loss : 0.612607, loss_ce: 0.376285
[10:09:12.031] iteration 22 : loss : 0.526959, loss_ce: 0.222933
[10:09:12.342] iteration 23 : loss : 0.504977, loss_ce: 0.166457
[10:09:12.650] iteration 24 : loss : 0.489976, loss_ce: 0.148743
[10:09:12.961] iteration 25 : loss : 0.505565, loss_ce: 0.177614
[10:09:13.273] iteration 26 : loss : 0.497987, loss_ce: 0.157799
[10:09:13.583] iteration 27 : loss : 0.538876, loss_ce: 0.236035
[10:09:13.891] iteration 28 : loss : 0.501428, loss_ce: 0.178504
[10:09:14.200] iteration 29 : loss : 0.483281, loss_ce: 0.145611
[10:09:14.509] iteration 30 : loss : 0.541367, loss_ce: 0.248420
[10:09:14.821] iteration 31 : loss : 0.501099, loss_ce: 0.189541
[10:09:15.131] iteration 32 : loss : 0.546664, loss_ce: 0.280596
[10:09:15.441] iteration 33 : loss : 0.476563, loss_ce: 0.164609
[10:09:15.749] iteration 34 : loss : 0.520614, loss_ce: 0.227240
[10:09:16.058] iteration 35 : loss : 0.547828, loss_ce: 0.274593
[10:09:16.368] iteration 36 : loss : 0.475363, loss_ce: 0.161585
[10:09:16.678] iteration 37 : loss : 0.492553, loss_ce: 0.153674
[10:09:16.988] iteration 38 : loss : 0.483979, loss_ce: 0.081319
[10:09:17.297] iteration 39 : loss : 0.573814, loss_ce: 0.292999
[10:09:17.607] iteration 40 : loss : 0.499268, loss_ce: 0.164305
[10:09:17.946] iteration 41 : loss : 0.553837, loss_ce: 0.261873
[10:09:18.255] iteration 42 : loss : 0.457591, loss_ce: 0.091200
[10:09:18.566] iteration 43 : loss : 0.574280, loss_ce: 0.313429
[10:09:18.877] iteration 44 : loss : 0.469185, loss_ce: 0.120176
[10:09:19.187] iteration 45 : loss : 0.509456, loss_ce: 0.196410
[10:09:19.496] iteration 46 : loss : 0.534522, loss_ce: 0.242506
[10:09:19.807] iteration 47 : loss : 0.516091, loss_ce: 0.217939
[10:09:20.117] iteration 48 : loss : 0.481418, loss_ce: 0.151848
[10:09:20.427] iteration 49 : loss : 0.478281, loss_ce: 0.143639
[10:09:20.738] iteration 50 : loss : 0.480364, loss_ce: 0.163490
[10:09:21.046] iteration 51 : loss : 0.589542, loss_ce: 0.343406
[10:09:21.355] iteration 52 : loss : 0.487882, loss_ce: 0.169725
[10:09:21.664] iteration 53 : loss : 0.537268, loss_ce: 0.254150
[10:09:21.975] iteration 54 : loss : 0.560528, loss_ce: 0.308468
[10:09:22.284] iteration 55 : loss : 0.483326, loss_ce: 0.164162
[10:09:22.594] iteration 56 : loss : 0.502500, loss_ce: 0.206602
[10:09:22.905] iteration 57 : loss : 0.462541, loss_ce: 0.120127
[10:09:23.213] iteration 58 : loss : 0.479866, loss_ce: 0.164737
[10:09:23.523] iteration 59 : loss : 0.540972, loss_ce: 0.280623
[10:09:23.836] iteration 60 : loss : 0.484040, loss_ce: 0.153069
[10:09:24.171] iteration 61 : loss : 0.456656, loss_ce: 0.082838
[10:09:24.480] iteration 62 : loss : 0.455600, loss_ce: 0.131512
[10:09:24.789] iteration 63 : loss : 0.525616, loss_ce: 0.232905
[10:09:25.098] iteration 64 : loss : 0.448966, loss_ce: 0.063900
[10:09:25.409] iteration 65 : loss : 0.454292, loss_ce: 0.097905
[10:09:25.719] iteration 66 : loss : 0.434826, loss_ce: 0.066352
[10:09:26.031] iteration 67 : loss : 0.465833, loss_ce: 0.140463
[10:09:26.342] iteration 68 : loss : 0.554448, loss_ce: 0.285565
[10:09:26.654] iteration 69 : loss : 0.511713, loss_ce: 0.237733
[10:09:26.963] iteration 70 : loss : 0.511021, loss_ce: 0.209446
[10:09:27.271] iteration 71 : loss : 0.497071, loss_ce: 0.183258
[10:09:27.583] iteration 72 : loss : 0.502439, loss_ce: 0.222960
[10:09:27.895] iteration 73 : loss : 0.481462, loss_ce: 0.159452
[10:09:28.205] iteration 74 : loss : 0.459364, loss_ce: 0.138536
[10:09:28.514] iteration 75 : loss : 0.497844, loss_ce: 0.215348
[10:09:28.826] iteration 76 : loss : 0.482597, loss_ce: 0.172218
[10:09:29.135] iteration 77 : loss : 0.460223, loss_ce: 0.134186
[10:09:29.446] iteration 78 : loss : 0.465825, loss_ce: 0.123389
[10:09:29.756] iteration 79 : loss : 0.508242, loss_ce: 0.201852
[10:09:30.066] iteration 80 : loss : 0.478046, loss_ce: 0.154310
[10:09:30.418] iteration 81 : loss : 0.488450, loss_ce: 0.158092
[10:09:30.727] iteration 82 : loss : 0.455832, loss_ce: 0.104300
[10:09:31.036] iteration 83 : loss : 0.438543, loss_ce: 0.103651
[10:09:31.344] iteration 84 : loss : 0.493971, loss_ce: 0.179618
[10:09:31.654] iteration 85 : loss : 0.470075, loss_ce: 0.145991
[10:09:31.964] iteration 86 : loss : 0.439812, loss_ce: 0.120293
[10:09:32.272] iteration 87 : loss : 0.460151, loss_ce: 0.140512
[10:09:32.583] iteration 88 : loss : 0.455952, loss_ce: 0.133141
[10:09:32.893] iteration 89 : loss : 0.473657, loss_ce: 0.175368
[10:09:33.205] iteration 90 : loss : 0.453709, loss_ce: 0.122533
[10:09:33.514] iteration 91 : loss : 0.506955, loss_ce: 0.234642
[10:09:33.826] iteration 92 : loss : 0.469595, loss_ce: 0.167025
[10:09:34.141] iteration 93 : loss : 0.459557, loss_ce: 0.157164
[10:09:34.450] iteration 94 : loss : 0.452825, loss_ce: 0.100392
[10:09:34.759] iteration 95 : loss : 0.501576, loss_ce: 0.218271
[10:09:35.068] iteration 96 : loss : 0.413391, loss_ce: 0.085389
[10:09:35.382] iteration 97 : loss : 0.490826, loss_ce: 0.211283
[10:09:35.695] iteration 98 : loss : 0.427714, loss_ce: 0.094045
[10:09:36.006] iteration 99 : loss : 0.447811, loss_ce: 0.097545
[10:09:36.316] iteration 100 : loss : 0.456051, loss_ce: 0.133220
[10:09:36.661] iteration 101 : loss : 0.428275, loss_ce: 0.086401
[10:09:36.971] iteration 102 : loss : 0.442630, loss_ce: 0.133347
[10:09:37.282] iteration 103 : loss : 0.441475, loss_ce: 0.106781
[10:09:37.593] iteration 104 : loss : 0.419964, loss_ce: 0.100115
[10:09:37.903] iteration 105 : loss : 0.530664, loss_ce: 0.259903
[10:09:38.210] iteration 106 : loss : 0.416774, loss_ce: 0.102376
[10:09:38.519] iteration 107 : loss : 0.462533, loss_ce: 0.186451
[10:09:38.831] iteration 108 : loss : 0.411404, loss_ce: 0.088115
[10:09:39.141] iteration 109 : loss : 0.470279, loss_ce: 0.123567
[10:09:39.450] iteration 110 : loss : 0.423137, loss_ce: 0.106969
[10:09:39.763] iteration 111 : loss : 0.455017, loss_ce: 0.165146
[10:09:40.071] iteration 112 : loss : 0.422864, loss_ce: 0.127802
[10:09:40.381] iteration 113 : loss : 0.482749, loss_ce: 0.089401
[10:09:40.694] iteration 114 : loss : 0.437329, loss_ce: 0.096477
[10:09:41.007] iteration 115 : loss : 0.432781, loss_ce: 0.125235
[10:09:41.316] iteration 116 : loss : 0.468321, loss_ce: 0.166884
[10:09:41.625] iteration 117 : loss : 0.439574, loss_ce: 0.132586
[10:09:41.934] iteration 118 : loss : 0.454534, loss_ce: 0.158495
[10:09:42.245] iteration 119 : loss : 0.499853, loss_ce: 0.237313
[10:09:42.557] iteration 120 : loss : 0.433169, loss_ce: 0.116476
[10:09:42.896] iteration 121 : loss : 0.495985, loss_ce: 0.238456
[10:09:43.205] iteration 122 : loss : 0.440941, loss_ce: 0.116966
[10:09:43.514] iteration 123 : loss : 0.460845, loss_ce: 0.115741
[10:09:43.825] iteration 124 : loss : 0.428178, loss_ce: 0.126541
[10:09:44.135] iteration 125 : loss : 0.444239, loss_ce: 0.151469
[10:09:44.446] iteration 126 : loss : 0.481016, loss_ce: 0.206614
[10:09:44.756] iteration 127 : loss : 0.421500, loss_ce: 0.084238
[10:09:45.066] iteration 128 : loss : 0.417149, loss_ce: 0.087968
[10:09:45.375] iteration 129 : loss : 0.422075, loss_ce: 0.124078
[10:09:45.683] iteration 130 : loss : 0.413539, loss_ce: 0.075095
[10:09:45.994] iteration 131 : loss : 0.453006, loss_ce: 0.149227
[10:09:46.303] iteration 132 : loss : 0.447913, loss_ce: 0.161136
[10:09:46.613] iteration 133 : loss : 0.493281, loss_ce: 0.234433
[10:09:46.922] iteration 134 : loss : 0.418358, loss_ce: 0.107229
[10:09:47.231] iteration 135 : loss : 0.408892, loss_ce: 0.117816
[10:09:47.542] iteration 136 : loss : 0.462219, loss_ce: 0.176609
[10:09:47.852] iteration 137 : loss : 0.419042, loss_ce: 0.118877
[10:09:48.162] iteration 138 : loss : 0.417093, loss_ce: 0.111322
[10:09:48.472] iteration 139 : loss : 0.471401, loss_ce: 0.183453
[10:09:48.781] iteration 140 : loss : 0.435187, loss_ce: 0.086487
[10:09:49.122] iteration 141 : loss : 0.417319, loss_ce: 0.119343
[10:09:49.430] iteration 142 : loss : 0.406326, loss_ce: 0.089644
[10:09:49.741] iteration 143 : loss : 0.415098, loss_ce: 0.111839
[10:09:50.050] iteration 144 : loss : 0.407686, loss_ce: 0.085789
[10:09:50.359] iteration 145 : loss : 0.459737, loss_ce: 0.156308
[10:09:50.668] iteration 146 : loss : 0.416242, loss_ce: 0.111741
[10:09:50.980] iteration 147 : loss : 0.435076, loss_ce: 0.086013
[10:09:51.290] iteration 148 : loss : 0.451720, loss_ce: 0.130197
[10:09:51.600] iteration 149 : loss : 0.435848, loss_ce: 0.131171
[10:09:51.912] iteration 150 : loss : 0.489087, loss_ce: 0.176027
[10:09:52.221] iteration 151 : loss : 0.401935, loss_ce: 0.063931
[10:09:52.531] iteration 152 : loss : 0.433027, loss_ce: 0.123891
[10:09:52.839] iteration 153 : loss : 0.456147, loss_ce: 0.155837
[10:09:53.148] iteration 154 : loss : 0.415945, loss_ce: 0.113201
[10:09:53.458] iteration 155 : loss : 0.445161, loss_ce: 0.169014
[10:09:53.766] iteration 156 : loss : 0.404537, loss_ce: 0.099369
[10:09:54.077] iteration 157 : loss : 0.431672, loss_ce: 0.144574
[10:09:54.391] iteration 158 : loss : 0.453567, loss_ce: 0.169714
[10:09:54.702] iteration 159 : loss : 0.430915, loss_ce: 0.123633
[10:09:55.012] iteration 160 : loss : 0.482174, loss_ce: 0.105653
[10:09:55.344] iteration 161 : loss : 0.429188, loss_ce: 0.115845
[10:09:55.651] iteration 162 : loss : 0.432971, loss_ce: 0.088484
[10:09:55.959] iteration 163 : loss : 0.560472, loss_ce: 0.333062
[10:09:56.272] iteration 164 : loss : 0.411599, loss_ce: 0.092109
[10:09:56.583] iteration 165 : loss : 0.453085, loss_ce: 0.137239
[10:09:56.894] iteration 166 : loss : 0.453508, loss_ce: 0.165378
[10:09:57.202] iteration 167 : loss : 0.458549, loss_ce: 0.147448
[10:09:57.511] iteration 168 : loss : 0.442909, loss_ce: 0.094643
[10:09:57.819] iteration 169 : loss : 0.482390, loss_ce: 0.090441
[10:09:58.129] iteration 170 : loss : 0.441404, loss_ce: 0.134220
[10:09:58.440] iteration 171 : loss : 0.441942, loss_ce: 0.142854
[10:09:58.749] iteration 172 : loss : 0.447373, loss_ce: 0.153988
[10:09:59.059] iteration 173 : loss : 0.408479, loss_ce: 0.075481
[10:09:59.369] iteration 174 : loss : 0.433432, loss_ce: 0.153214
[10:09:59.680] iteration 175 : loss : 0.431345, loss_ce: 0.154026
[10:09:59.990] iteration 176 : loss : 0.404619, loss_ce: 0.102899
[10:10:00.300] iteration 177 : loss : 0.413373, loss_ce: 0.114691
[10:10:00.610] iteration 178 : loss : 0.412166, loss_ce: 0.105754
[10:10:00.921] iteration 179 : loss : 0.451354, loss_ce: 0.184627
[10:10:01.231] iteration 180 : loss : 0.451718, loss_ce: 0.175514
[10:10:01.570] iteration 181 : loss : 0.463835, loss_ce: 0.168883
[10:10:01.880] iteration 182 : loss : 0.475740, loss_ce: 0.105430
[10:10:02.188] iteration 183 : loss : 0.415229, loss_ce: 0.090363
[10:10:02.498] iteration 184 : loss : 0.412321, loss_ce: 0.126393
[10:10:02.810] iteration 185 : loss : 0.415949, loss_ce: 0.129490
[10:10:03.119] iteration 186 : loss : 0.412087, loss_ce: 0.126532
[10:10:03.430] iteration 187 : loss : 0.402081, loss_ce: 0.111911
[10:10:03.737] iteration 188 : loss : 0.468490, loss_ce: 0.200763
[10:10:04.046] iteration 189 : loss : 0.414928, loss_ce: 0.123376
[10:10:04.355] iteration 190 : loss : 0.451383, loss_ce: 0.131304
[10:10:04.667] iteration 191 : loss : 0.449102, loss_ce: 0.186814
[10:10:04.976] iteration 192 : loss : 0.395934, loss_ce: 0.083235
[10:10:05.287] iteration 193 : loss : 0.424734, loss_ce: 0.140633
[10:10:05.598] iteration 194 : loss : 0.436726, loss_ce: 0.154194
[10:10:05.910] iteration 195 : loss : 0.419753, loss_ce: 0.109184
[10:10:06.219] iteration 196 : loss : 0.408746, loss_ce: 0.110225
[10:10:06.529] iteration 197 : loss : 0.464634, loss_ce: 0.113876
[10:10:06.838] iteration 198 : loss : 0.436312, loss_ce: 0.127278
[10:10:07.148] iteration 199 : loss : 0.424932, loss_ce: 0.134762
[10:10:07.458] iteration 200 : loss : 0.393552, loss_ce: 0.094538
[10:10:07.796] iteration 201 : loss : 0.394444, loss_ce: 0.094817
[10:10:08.107] iteration 202 : loss : 0.439369, loss_ce: 0.125424
[10:10:08.418] iteration 203 : loss : 0.477599, loss_ce: 0.183928
[10:10:08.730] iteration 204 : loss : 0.456824, loss_ce: 0.191558
[10:10:09.040] iteration 205 : loss : 0.415561, loss_ce: 0.107573
[10:10:09.348] iteration 206 : loss : 0.478506, loss_ce: 0.152990
[10:10:09.658] iteration 207 : loss : 0.416933, loss_ce: 0.134699
[10:10:09.970] iteration 208 : loss : 0.406264, loss_ce: 0.102586
[10:10:10.280] iteration 209 : loss : 0.438378, loss_ce: 0.157856
[10:10:10.592] iteration 210 : loss : 0.384095, loss_ce: 0.081723
[10:10:10.908] iteration 211 : loss : 0.409162, loss_ce: 0.101828
[10:10:11.217] iteration 212 : loss : 0.413660, loss_ce: 0.100329
[10:10:11.526] iteration 213 : loss : 0.420027, loss_ce: 0.106780
[10:10:11.836] iteration 214 : loss : 0.410474, loss_ce: 0.113043
[10:10:12.146] iteration 215 : loss : 0.413928, loss_ce: 0.083697
[10:10:12.457] iteration 216 : loss : 0.416551, loss_ce: 0.106766
[10:10:12.765] iteration 217 : loss : 0.398746, loss_ce: 0.085778
[10:10:13.074] iteration 218 : loss : 0.399253, loss_ce: 0.059508
[10:10:13.383] iteration 219 : loss : 0.418660, loss_ce: 0.113249
[10:10:13.693] iteration 220 : loss : 0.427731, loss_ce: 0.151665
[10:10:14.028] iteration 221 : loss : 0.412088, loss_ce: 0.076267
[10:10:14.338] iteration 222 : loss : 0.400977, loss_ce: 0.085716
[10:10:14.649] iteration 223 : loss : 0.428075, loss_ce: 0.082687
[10:10:14.960] iteration 224 : loss : 0.502763, loss_ce: 0.256254
[10:10:15.268] iteration 225 : loss : 0.426012, loss_ce: 0.088193
[10:10:15.579] iteration 226 : loss : 0.435871, loss_ce: 0.151259
[10:10:15.890] iteration 227 : loss : 0.401751, loss_ce: 0.083631
[10:10:16.204] iteration 228 : loss : 0.422148, loss_ce: 0.138410
[10:10:16.517] iteration 229 : loss : 0.401723, loss_ce: 0.096145
[10:10:16.826] iteration 230 : loss : 0.394933, loss_ce: 0.087838
[10:10:17.134] iteration 231 : loss : 0.430515, loss_ce: 0.153690
[10:10:17.446] iteration 232 : loss : 0.402537, loss_ce: 0.099264
[10:10:17.756] iteration 233 : loss : 0.384524, loss_ce: 0.077680
[10:10:18.069] iteration 234 : loss : 0.438072, loss_ce: 0.160884
[10:10:18.379] iteration 235 : loss : 0.405610, loss_ce: 0.093505
[10:10:18.687] iteration 236 : loss : 0.403368, loss_ce: 0.084237
[10:10:18.995] iteration 237 : loss : 0.400386, loss_ce: 0.089868
[10:10:19.304] iteration 238 : loss : 0.388376, loss_ce: 0.087626
[10:10:19.615] iteration 239 : loss : 0.391748, loss_ce: 0.083584
[10:10:19.925] iteration 240 : loss : 0.375910, loss_ce: 0.066417
[10:10:20.260] iteration 241 : loss : 0.397276, loss_ce: 0.059617
[10:10:20.572] iteration 242 : loss : 0.423090, loss_ce: 0.117468
[10:10:20.882] iteration 243 : loss : 0.438476, loss_ce: 0.136309
[10:10:21.193] iteration 244 : loss : 0.392709, loss_ce: 0.046336
[10:10:21.503] iteration 245 : loss : 0.404520, loss_ce: 0.099629
[10:10:21.814] iteration 246 : loss : 0.394343, loss_ce: 0.075698
[10:10:22.124] iteration 247 : loss : 0.384382, loss_ce: 0.058173
[10:10:22.433] iteration 248 : loss : 0.428076, loss_ce: 0.141773
[10:10:22.745] iteration 249 : loss : 0.397479, loss_ce: 0.091654
[10:10:23.055] iteration 250 : loss : 0.418083, loss_ce: 0.116046
[10:10:23.366] iteration 251 : loss : 0.437463, loss_ce: 0.156017
[10:10:23.677] iteration 252 : loss : 0.409724, loss_ce: 0.111279
[10:10:23.985] iteration 253 : loss : 0.399087, loss_ce: 0.102059
[10:10:24.293] iteration 254 : loss : 0.440819, loss_ce: 0.168453
[10:10:24.604] iteration 255 : loss : 0.409387, loss_ce: 0.123685
[10:10:24.913] iteration 256 : loss : 0.464510, loss_ce: 0.131485
[10:10:25.224] iteration 257 : loss : 0.423295, loss_ce: 0.116534
[10:10:25.536] iteration 258 : loss : 0.411658, loss_ce: 0.109821
[10:10:25.845] iteration 259 : loss : 0.397918, loss_ce: 0.105065
[10:10:26.154] iteration 260 : loss : 0.392238, loss_ce: 0.093183
[10:10:26.486] iteration 261 : loss : 0.410339, loss_ce: 0.126665
[10:10:26.803] iteration 262 : loss : 0.413161, loss_ce: 0.085340
[10:10:27.113] iteration 263 : loss : 0.400853, loss_ce: 0.100868
[10:10:27.424] iteration 264 : loss : 0.389497, loss_ce: 0.066461
[10:10:27.733] iteration 265 : loss : 0.405127, loss_ce: 0.097087
[10:10:28.042] iteration 266 : loss : 0.409800, loss_ce: 0.114736
[10:10:28.352] iteration 267 : loss : 0.391171, loss_ce: 0.085255
[10:10:28.665] iteration 268 : loss : 0.466774, loss_ce: 0.197681
[10:10:28.975] iteration 269 : loss : 0.409614, loss_ce: 0.103659
[10:10:29.285] iteration 270 : loss : 0.414896, loss_ce: 0.059383
[10:10:29.597] iteration 271 : loss : 0.411421, loss_ce: 0.120107
[10:10:29.906] iteration 272 : loss : 0.430223, loss_ce: 0.133427
[10:10:30.217] iteration 273 : loss : 0.425226, loss_ce: 0.074276
[10:10:30.528] iteration 274 : loss : 0.400647, loss_ce: 0.070932
[10:10:30.838] iteration 275 : loss : 0.431258, loss_ce: 0.149371
[10:10:31.146] iteration 276 : loss : 0.407558, loss_ce: 0.089899
[10:10:31.317] iteration 277 : loss : 0.474517, loss_ce: 0.189577
[10:10:32.128] iteration 278 : loss : 0.422714, loss_ce: 0.128077
[10:10:32.437] iteration 279 : loss : 0.402146, loss_ce: 0.087341
[10:10:32.747] iteration 280 : loss : 0.402605, loss_ce: 0.080433
[10:10:33.084] iteration 281 : loss : 0.415539, loss_ce: 0.077013
[10:10:33.395] iteration 282 : loss : 0.384564, loss_ce: 0.074662
[10:10:33.707] iteration 283 : loss : 0.412034, loss_ce: 0.049457
[10:10:34.017] iteration 284 : loss : 0.411939, loss_ce: 0.105952
[10:10:34.328] iteration 285 : loss : 0.388369, loss_ce: 0.079180
[10:10:34.639] iteration 286 : loss : 0.414177, loss_ce: 0.116228
[10:10:34.951] iteration 287 : loss : 0.407313, loss_ce: 0.071008
[10:10:35.267] iteration 288 : loss : 0.415071, loss_ce: 0.125653
[10:10:35.578] iteration 289 : loss : 0.445862, loss_ce: 0.150331
[10:10:35.886] iteration 290 : loss : 0.374462, loss_ce: 0.054467
[10:10:36.195] iteration 291 : loss : 0.396874, loss_ce: 0.088316
[10:10:36.506] iteration 292 : loss : 0.388977, loss_ce: 0.049867
[10:10:36.818] iteration 293 : loss : 0.407907, loss_ce: 0.097060
[10:10:37.126] iteration 294 : loss : 0.459169, loss_ce: 0.201582
[10:10:37.439] iteration 295 : loss : 0.415687, loss_ce: 0.120490
[10:10:37.748] iteration 296 : loss : 0.398612, loss_ce: 0.061452
[10:10:38.058] iteration 297 : loss : 0.400285, loss_ce: 0.077686
[10:10:38.370] iteration 298 : loss : 0.410425, loss_ce: 0.112436
[10:10:38.682] iteration 299 : loss : 0.411324, loss_ce: 0.082405
[10:10:38.993] iteration 300 : loss : 0.452167, loss_ce: 0.076978
[10:10:39.326] iteration 301 : loss : 0.403237, loss_ce: 0.102608
[10:10:39.639] iteration 302 : loss : 0.378257, loss_ce: 0.068713
[10:10:39.953] iteration 303 : loss : 0.393920, loss_ce: 0.058920
[10:10:40.265] iteration 304 : loss : 0.413572, loss_ce: 0.118479
[10:10:40.575] iteration 305 : loss : 0.386308, loss_ce: 0.078885
[10:10:40.886] iteration 306 : loss : 0.424996, loss_ce: 0.128535
[10:10:41.198] iteration 307 : loss : 0.386557, loss_ce: 0.066259
[10:10:41.509] iteration 308 : loss : 0.428588, loss_ce: 0.140320
[10:10:41.820] iteration 309 : loss : 0.385174, loss_ce: 0.082079
[10:10:42.130] iteration 310 : loss : 0.413180, loss_ce: 0.113142
[10:10:42.440] iteration 311 : loss : 0.400627, loss_ce: 0.105505
[10:10:42.749] iteration 312 : loss : 0.392440, loss_ce: 0.100709
[10:10:43.060] iteration 313 : loss : 0.419930, loss_ce: 0.130817
[10:10:43.370] iteration 314 : loss : 0.408384, loss_ce: 0.124084
[10:10:43.681] iteration 315 : loss : 0.414929, loss_ce: 0.104635
[10:10:43.994] iteration 316 : loss : 0.421687, loss_ce: 0.135017
[10:10:44.308] iteration 317 : loss : 0.408483, loss_ce: 0.112568
[10:10:44.617] iteration 318 : loss : 0.437006, loss_ce: 0.170326
[10:10:44.927] iteration 319 : loss : 0.396621, loss_ce: 0.107238
[10:10:45.238] iteration 320 : loss : 0.387998, loss_ce: 0.069840
[10:10:45.575] iteration 321 : loss : 0.412328, loss_ce: 0.133217
[10:10:45.886] iteration 322 : loss : 0.422877, loss_ce: 0.122493
[10:10:46.194] iteration 323 : loss : 0.391562, loss_ce: 0.091598
[10:10:46.503] iteration 324 : loss : 0.391462, loss_ce: 0.088681
[10:10:46.813] iteration 325 : loss : 0.412690, loss_ce: 0.060022
[10:10:47.123] iteration 326 : loss : 0.406992, loss_ce: 0.107213
[10:10:47.434] iteration 327 : loss : 0.389410, loss_ce: 0.090604
[10:10:47.744] iteration 328 : loss : 0.385010, loss_ce: 0.069805
[10:10:48.057] iteration 329 : loss : 0.411636, loss_ce: 0.107609
[10:10:48.367] iteration 330 : loss : 0.410410, loss_ce: 0.070465
[10:10:48.679] iteration 331 : loss : 0.415914, loss_ce: 0.128227
[10:10:48.989] iteration 332 : loss : 0.392458, loss_ce: 0.084655
[10:10:49.300] iteration 333 : loss : 0.421701, loss_ce: 0.104798
[10:10:49.609] iteration 334 : loss : 0.416188, loss_ce: 0.138906
[10:10:49.920] iteration 335 : loss : 0.408647, loss_ce: 0.112013
[10:10:50.229] iteration 336 : loss : 0.454139, loss_ce: 0.200727
[10:10:50.540] iteration 337 : loss : 0.407334, loss_ce: 0.126515
[10:10:50.850] iteration 338 : loss : 0.386730, loss_ce: 0.098422
[10:10:51.161] iteration 339 : loss : 0.432937, loss_ce: 0.140956
[10:10:51.476] iteration 340 : loss : 0.405375, loss_ce: 0.118420
[10:10:51.827] iteration 341 : loss : 0.417673, loss_ce: 0.148498
[10:10:52.137] iteration 342 : loss : 0.443003, loss_ce: 0.100128
[10:10:52.449] iteration 343 : loss : 0.419161, loss_ce: 0.128608
[10:10:52.761] iteration 344 : loss : 0.455032, loss_ce: 0.105031
[10:10:53.071] iteration 345 : loss : 0.403057, loss_ce: 0.115684
[10:10:53.381] iteration 346 : loss : 0.393029, loss_ce: 0.088138
[10:10:53.696] iteration 347 : loss : 0.410751, loss_ce: 0.086151
[10:10:54.009] iteration 348 : loss : 0.418440, loss_ce: 0.062663
[10:10:54.320] iteration 349 : loss : 0.388643, loss_ce: 0.070046
[10:10:54.636] iteration 350 : loss : 0.425884, loss_ce: 0.060414
[10:10:54.947] iteration 351 : loss : 0.432063, loss_ce: 0.143681
[10:10:55.257] iteration 352 : loss : 0.401206, loss_ce: 0.059220
[10:10:55.567] iteration 353 : loss : 0.391814, loss_ce: 0.078471
[10:10:55.878] iteration 354 : loss : 0.371722, loss_ce: 0.037959
[10:10:56.190] iteration 355 : loss : 0.486646, loss_ce: 0.235295
[10:10:56.501] iteration 356 : loss : 0.404715, loss_ce: 0.120295
[10:10:56.812] iteration 357 : loss : 0.429659, loss_ce: 0.148459
[10:10:57.124] iteration 358 : loss : 0.397796, loss_ce: 0.103330
[10:10:57.434] iteration 359 : loss : 0.407970, loss_ce: 0.110027
[10:10:57.746] iteration 360 : loss : 0.388954, loss_ce: 0.081851
[10:10:58.076] iteration 361 : loss : 0.423058, loss_ce: 0.111045
[10:10:58.387] iteration 362 : loss : 0.513013, loss_ce: 0.156846
[10:10:58.698] iteration 363 : loss : 0.427347, loss_ce: 0.125025
[10:10:59.009] iteration 364 : loss : 0.496699, loss_ce: 0.137601
[10:10:59.319] iteration 365 : loss : 0.439319, loss_ce: 0.183254
[10:10:59.630] iteration 366 : loss : 0.389933, loss_ce: 0.089445
[10:10:59.941] iteration 367 : loss : 0.415186, loss_ce: 0.077707
[10:11:00.255] iteration 368 : loss : 0.484916, loss_ce: 0.120427
[10:11:00.564] iteration 369 : loss : 0.434487, loss_ce: 0.163278
[10:11:00.877] iteration 370 : loss : 0.392789, loss_ce: 0.082780
[10:11:01.187] iteration 371 : loss : 0.429398, loss_ce: 0.155018
[10:11:01.500] iteration 372 : loss : 0.400826, loss_ce: 0.074090
[10:11:01.810] iteration 373 : loss : 0.416484, loss_ce: 0.110781
[10:11:02.120] iteration 374 : loss : 0.451171, loss_ce: 0.083084
[10:11:02.434] iteration 375 : loss : 0.442754, loss_ce: 0.145377
[10:11:02.744] iteration 376 : loss : 0.380748, loss_ce: 0.048982
[10:11:03.054] iteration 377 : loss : 0.442854, loss_ce: 0.173577
[10:11:03.367] iteration 378 : loss : 0.399068, loss_ce: 0.048578
[10:11:03.677] iteration 379 : loss : 0.409257, loss_ce: 0.071871
[10:11:03.992] iteration 380 : loss : 0.390267, loss_ce: 0.094806
[10:11:04.349] iteration 381 : loss : 0.417641, loss_ce: 0.130614
[10:11:04.662] iteration 382 : loss : 0.403318, loss_ce: 0.113363
[10:11:04.973] iteration 383 : loss : 0.423022, loss_ce: 0.148103
[10:11:05.283] iteration 384 : loss : 0.384206, loss_ce: 0.081302
[10:11:05.592] iteration 385 : loss : 0.408269, loss_ce: 0.129379
[10:11:05.906] iteration 386 : loss : 0.407477, loss_ce: 0.142012
[10:11:06.216] iteration 387 : loss : 0.409799, loss_ce: 0.138826
[10:11:06.529] iteration 388 : loss : 0.444319, loss_ce: 0.074829
[10:11:06.839] iteration 389 : loss : 0.389025, loss_ce: 0.116629
[10:11:07.149] iteration 390 : loss : 0.406743, loss_ce: 0.132367
[10:11:07.463] iteration 391 : loss : 0.396543, loss_ce: 0.091498
[10:11:07.774] iteration 392 : loss : 0.401973, loss_ce: 0.107284
[10:11:08.088] iteration 393 : loss : 0.443797, loss_ce: 0.072243
[10:11:08.397] iteration 394 : loss : 0.417073, loss_ce: 0.134523
[10:11:08.708] iteration 395 : loss : 0.410919, loss_ce: 0.095285
[10:11:09.018] iteration 396 : loss : 0.427310, loss_ce: 0.164945
[10:11:09.328] iteration 397 : loss : 0.378749, loss_ce: 0.056071
[10:11:09.638] iteration 398 : loss : 0.443431, loss_ce: 0.100235
[10:11:09.948] iteration 399 : loss : 0.405018, loss_ce: 0.113534
[10:11:10.259] iteration 400 : loss : 0.420694, loss_ce: 0.138597
[10:11:10.592] iteration 401 : loss : 0.414412, loss_ce: 0.058702
[10:11:10.904] iteration 402 : loss : 0.397134, loss_ce: 0.061540
[10:11:11.219] iteration 403 : loss : 0.422154, loss_ce: 0.133224
[10:11:11.529] iteration 404 : loss : 0.424251, loss_ce: 0.134928
[10:11:11.843] iteration 405 : loss : 0.406420, loss_ce: 0.121722
[10:11:12.151] iteration 406 : loss : 0.407278, loss_ce: 0.126135
[10:11:12.463] iteration 407 : loss : 0.386094, loss_ce: 0.072008
[10:11:12.774] iteration 408 : loss : 0.381391, loss_ce: 0.060687
[10:11:13.086] iteration 409 : loss : 0.379777, loss_ce: 0.085225
[10:11:13.397] iteration 410 : loss : 0.437105, loss_ce: 0.177696
[10:11:13.707] iteration 411 : loss : 0.412621, loss_ce: 0.057039
[10:11:14.017] iteration 412 : loss : 0.405189, loss_ce: 0.106670
[10:11:14.326] iteration 413 : loss : 0.426252, loss_ce: 0.152275
[10:11:14.638] iteration 414 : loss : 0.424215, loss_ce: 0.158457
[10:11:14.949] iteration 415 : loss : 0.375344, loss_ce: 0.085234
[10:11:15.260] iteration 416 : loss : 0.384467, loss_ce: 0.090346
[10:11:15.570] iteration 417 : loss : 0.414110, loss_ce: 0.062003
[10:11:15.881] iteration 418 : loss : 0.406833, loss_ce: 0.108881
[10:11:16.192] iteration 419 : loss : 0.396583, loss_ce: 0.087929
[10:11:16.502] iteration 420 : loss : 0.383804, loss_ce: 0.098253
[10:11:16.842] iteration 421 : loss : 0.400410, loss_ce: 0.107346
[10:11:17.154] iteration 422 : loss : 0.377375, loss_ce: 0.067619
[10:11:17.464] iteration 423 : loss : 0.381902, loss_ce: 0.062335
[10:11:17.772] iteration 424 : loss : 0.400785, loss_ce: 0.119755
[10:11:18.082] iteration 425 : loss : 0.414010, loss_ce: 0.099109
[10:11:18.395] iteration 426 : loss : 0.365589, loss_ce: 0.062960
[10:11:18.706] iteration 427 : loss : 0.404657, loss_ce: 0.094617
[10:11:19.018] iteration 428 : loss : 0.393762, loss_ce: 0.083786
[10:11:19.327] iteration 429 : loss : 0.415808, loss_ce: 0.131734
[10:11:19.636] iteration 430 : loss : 0.439023, loss_ce: 0.103115
[10:11:19.947] iteration 431 : loss : 0.404952, loss_ce: 0.126682
[10:11:20.258] iteration 432 : loss : 0.374853, loss_ce: 0.083867
[10:11:20.570] iteration 433 : loss : 0.389471, loss_ce: 0.109721
[10:11:20.886] iteration 434 : loss : 0.397706, loss_ce: 0.110057
[10:11:21.195] iteration 435 : loss : 0.374642, loss_ce: 0.074883
[10:11:21.504] iteration 436 : loss : 0.447138, loss_ce: 0.186457
[10:11:21.815] iteration 437 : loss : 0.390927, loss_ce: 0.068043
[10:11:22.125] iteration 438 : loss : 0.375372, loss_ce: 0.070650
[10:11:22.436] iteration 439 : loss : 0.419704, loss_ce: 0.157413
[10:11:22.746] iteration 440 : loss : 0.384857, loss_ce: 0.090621
[10:11:23.081] iteration 441 : loss : 0.402818, loss_ce: 0.135465
[10:11:23.391] iteration 442 : loss : 0.383955, loss_ce: 0.060699
[10:11:23.702] iteration 443 : loss : 0.378248, loss_ce: 0.060734
[10:11:24.013] iteration 444 : loss : 0.375145, loss_ce: 0.072622
[10:11:24.323] iteration 445 : loss : 0.383073, loss_ce: 0.070310
[10:11:24.634] iteration 446 : loss : 0.398563, loss_ce: 0.080712
[10:11:24.948] iteration 447 : loss : 0.380767, loss_ce: 0.085324
[10:11:25.261] iteration 448 : loss : 0.426822, loss_ce: 0.169247
[10:11:25.576] iteration 449 : loss : 0.395568, loss_ce: 0.089951
[10:11:25.887] iteration 450 : loss : 0.373223, loss_ce: 0.042052
[10:11:26.198] iteration 451 : loss : 0.417305, loss_ce: 0.106897
[10:11:26.508] iteration 452 : loss : 0.424662, loss_ce: 0.056637
[10:11:26.816] iteration 453 : loss : 0.358969, loss_ce: 0.061407
[10:11:27.125] iteration 454 : loss : 0.357872, loss_ce: 0.049688
[10:11:27.435] iteration 455 : loss : 0.386530, loss_ce: 0.095023
[10:11:27.745] iteration 456 : loss : 0.393729, loss_ce: 0.071190
[10:11:28.057] iteration 457 : loss : 0.388042, loss_ce: 0.094602
[10:11:28.366] iteration 458 : loss : 0.418465, loss_ce: 0.112810
[10:11:28.677] iteration 459 : loss : 0.389484, loss_ce: 0.033408
[10:11:28.987] iteration 460 : loss : 0.400813, loss_ce: 0.102862
[10:11:29.323] iteration 461 : loss : 0.403091, loss_ce: 0.134717
[10:11:29.632] iteration 462 : loss : 0.374939, loss_ce: 0.072851
[10:11:29.943] iteration 463 : loss : 0.397482, loss_ce: 0.126638
[10:11:30.254] iteration 464 : loss : 0.370000, loss_ce: 0.062493
[10:11:30.564] iteration 465 : loss : 0.390909, loss_ce: 0.102665
[10:11:30.876] iteration 466 : loss : 0.360435, loss_ce: 0.080817
[10:11:31.187] iteration 467 : loss : 0.352997, loss_ce: 0.067429
[10:11:31.497] iteration 468 : loss : 0.407793, loss_ce: 0.141229
[10:11:31.809] iteration 469 : loss : 0.369457, loss_ce: 0.070485
[10:11:32.120] iteration 470 : loss : 0.382968, loss_ce: 0.103091
[10:11:32.430] iteration 471 : loss : 0.371709, loss_ce: 0.087543
[10:11:32.739] iteration 472 : loss : 0.396725, loss_ce: 0.114790
[10:11:33.052] iteration 473 : loss : 0.377992, loss_ce: 0.100790
[10:11:33.363] iteration 474 : loss : 0.397368, loss_ce: 0.116210
[10:11:33.676] iteration 475 : loss : 0.380997, loss_ce: 0.106856
[10:11:33.988] iteration 476 : loss : 0.398332, loss_ce: 0.066791
[10:11:34.298] iteration 477 : loss : 0.368665, loss_ce: 0.102219
[10:11:34.607] iteration 478 : loss : 0.387973, loss_ce: 0.108662
[10:11:34.917] iteration 479 : loss : 0.369721, loss_ce: 0.093466
[10:11:35.227] iteration 480 : loss : 0.415652, loss_ce: 0.073702
[10:11:35.563] iteration 481 : loss : 0.377165, loss_ce: 0.104012
[10:11:35.879] iteration 482 : loss : 0.353216, loss_ce: 0.066131
[10:11:36.188] iteration 483 : loss : 0.363874, loss_ce: 0.052005
[10:11:36.498] iteration 484 : loss : 0.409588, loss_ce: 0.049378
[10:11:36.809] iteration 485 : loss : 0.380592, loss_ce: 0.116645
[10:11:37.121] iteration 486 : loss : 0.368896, loss_ce: 0.064914
[10:11:37.432] iteration 487 : loss : 0.397036, loss_ce: 0.125735
[10:11:37.744] iteration 488 : loss : 0.443743, loss_ce: 0.081282
[10:11:38.056] iteration 489 : loss : 0.375381, loss_ce: 0.096035
[10:11:38.369] iteration 490 : loss : 0.390264, loss_ce: 0.115474
[10:11:38.683] iteration 491 : loss : 0.365745, loss_ce: 0.080795
[10:11:38.996] iteration 492 : loss : 0.355195, loss_ce: 0.067364
[10:11:39.308] iteration 493 : loss : 0.364444, loss_ce: 0.063014
[10:11:39.620] iteration 494 : loss : 0.389118, loss_ce: 0.099715
[10:11:39.930] iteration 495 : loss : 0.366702, loss_ce: 0.088524
[10:11:40.240] iteration 496 : loss : 0.363230, loss_ce: 0.111363
[10:11:40.552] iteration 497 : loss : 0.426955, loss_ce: 0.142503
[10:11:40.863] iteration 498 : loss : 0.371160, loss_ce: 0.086430
[10:11:41.173] iteration 499 : loss : 0.364001, loss_ce: 0.075263
[10:11:41.483] iteration 500 : loss : 0.355648, loss_ce: 0.084229
[10:11:41.814] iteration 501 : loss : 0.361767, loss_ce: 0.087088
[10:11:42.125] iteration 502 : loss : 0.390740, loss_ce: 0.104461
[10:11:42.435] iteration 503 : loss : 0.418882, loss_ce: 0.081233
[10:11:42.746] iteration 504 : loss : 0.397202, loss_ce: 0.038307
[10:11:43.058] iteration 505 : loss : 0.390661, loss_ce: 0.106325
[10:11:43.368] iteration 506 : loss : 0.412445, loss_ce: 0.144836
[10:11:43.679] iteration 507 : loss : 0.469215, loss_ce: 0.232207
[10:11:43.990] iteration 508 : loss : 0.405313, loss_ce: 0.130359
[10:11:44.301] iteration 509 : loss : 0.379819, loss_ce: 0.120439
[10:11:44.614] iteration 510 : loss : 0.345788, loss_ce: 0.079439
[10:11:44.923] iteration 511 : loss : 0.364239, loss_ce: 0.112859
[10:11:45.231] iteration 512 : loss : 0.394596, loss_ce: 0.151580
[10:11:45.540] iteration 513 : loss : 0.427025, loss_ce: 0.132149
[10:11:45.851] iteration 514 : loss : 0.411091, loss_ce: 0.127312
[10:11:46.163] iteration 515 : loss : 0.495096, loss_ce: 0.111301
[10:11:46.476] iteration 516 : loss : 0.415142, loss_ce: 0.074131
[10:11:46.788] iteration 517 : loss : 0.442154, loss_ce: 0.160376
[10:11:47.099] iteration 518 : loss : 0.407122, loss_ce: 0.091653
[10:11:47.407] iteration 519 : loss : 0.413716, loss_ce: 0.129837
[10:11:47.718] iteration 520 : loss : 0.385808, loss_ce: 0.111074
[10:11:48.058] iteration 521 : loss : 0.371391, loss_ce: 0.117968
[10:11:48.372] iteration 522 : loss : 0.407973, loss_ce: 0.162619
[10:11:48.684] iteration 523 : loss : 0.369821, loss_ce: 0.107423
[10:11:48.993] iteration 524 : loss : 0.417038, loss_ce: 0.107056
[10:11:49.307] iteration 525 : loss : 0.385681, loss_ce: 0.117991
[10:11:49.619] iteration 526 : loss : 0.386472, loss_ce: 0.125256
[10:11:49.935] iteration 527 : loss : 0.372779, loss_ce: 0.085418
[10:11:50.245] iteration 528 : loss : 0.422508, loss_ce: 0.163836
[10:11:50.556] iteration 529 : loss : 0.353259, loss_ce: 0.091055
[10:11:50.867] iteration 530 : loss : 0.403190, loss_ce: 0.151240
[10:11:51.178] iteration 531 : loss : 0.396582, loss_ce: 0.062634
[10:11:51.489] iteration 532 : loss : 0.409983, loss_ce: 0.123413
[10:11:51.800] iteration 533 : loss : 0.343084, loss_ce: 0.086579
[10:11:52.116] iteration 534 : loss : 0.388375, loss_ce: 0.125345
[10:11:52.424] iteration 535 : loss : 0.362497, loss_ce: 0.095925
[10:11:52.733] iteration 536 : loss : 0.388000, loss_ce: 0.114025
[10:11:53.047] iteration 537 : loss : 0.348560, loss_ce: 0.050209
[10:11:53.358] iteration 538 : loss : 0.423060, loss_ce: 0.178371
[10:11:53.670] iteration 539 : loss : 0.431042, loss_ce: 0.094515
[10:11:53.981] iteration 540 : loss : 0.359470, loss_ce: 0.108574
[10:11:54.312] iteration 541 : loss : 0.395108, loss_ce: 0.104272
[10:11:54.627] iteration 542 : loss : 0.351135, loss_ce: 0.084336
[10:11:54.938] iteration 543 : loss : 0.409597, loss_ce: 0.162286
[10:11:55.249] iteration 544 : loss : 0.343486, loss_ce: 0.080534
[10:11:55.562] iteration 545 : loss : 0.396953, loss_ce: 0.133603
[10:11:55.874] iteration 546 : loss : 0.346951, loss_ce: 0.091222
[10:11:56.184] iteration 547 : loss : 0.357887, loss_ce: 0.101867
[10:11:56.494] iteration 548 : loss : 0.330616, loss_ce: 0.092827
[10:11:56.806] iteration 549 : loss : 0.381626, loss_ce: 0.071753
[10:11:57.116] iteration 550 : loss : 0.351645, loss_ce: 0.100979
[10:11:57.427] iteration 551 : loss : 0.351899, loss_ce: 0.074729
[10:11:57.737] iteration 552 : loss : 0.320100, loss_ce: 0.066404
[10:11:58.046] iteration 553 : loss : 0.346029, loss_ce: 0.055561
[10:11:58.209] iteration 554 : loss : 0.404559, loss_ce: 0.055813
[10:11:59.014] iteration 555 : loss : 0.445072, loss_ce: 0.128491
[10:11:59.326] iteration 556 : loss : 0.395250, loss_ce: 0.079068
[10:11:59.636] iteration 557 : loss : 0.399361, loss_ce: 0.055923
[10:11:59.948] iteration 558 : loss : 0.464450, loss_ce: 0.212356
[10:12:00.257] iteration 559 : loss : 0.328312, loss_ce: 0.063315
[10:12:00.567] iteration 560 : loss : 0.367070, loss_ce: 0.102610
[10:12:00.916] iteration 561 : loss : 0.381976, loss_ce: 0.095182
[10:12:01.226] iteration 562 : loss : 0.354204, loss_ce: 0.097322
[10:12:01.538] iteration 563 : loss : 0.370190, loss_ce: 0.121761
[10:12:01.849] iteration 564 : loss : 0.399339, loss_ce: 0.122563
[10:12:02.162] iteration 565 : loss : 0.348542, loss_ce: 0.086571
[10:12:02.472] iteration 566 : loss : 0.370567, loss_ce: 0.121299
[10:12:02.783] iteration 567 : loss : 0.354570, loss_ce: 0.075818
[10:12:03.093] iteration 568 : loss : 0.345806, loss_ce: 0.097810
[10:12:03.405] iteration 569 : loss : 0.409263, loss_ce: 0.096085
[10:12:03.719] iteration 570 : loss : 0.339811, loss_ce: 0.046068
[10:12:04.030] iteration 571 : loss : 0.384542, loss_ce: 0.091327
[10:12:04.339] iteration 572 : loss : 0.338187, loss_ce: 0.070415
[10:12:04.651] iteration 573 : loss : 0.377910, loss_ce: 0.110810
[10:12:04.962] iteration 574 : loss : 0.346323, loss_ce: 0.048210
[10:12:05.273] iteration 575 : loss : 0.369714, loss_ce: 0.119932
[10:12:05.583] iteration 576 : loss : 0.331781, loss_ce: 0.048729
[10:12:05.893] iteration 577 : loss : 0.376256, loss_ce: 0.126693
[10:12:06.205] iteration 578 : loss : 0.396082, loss_ce: 0.102597
[10:12:06.516] iteration 579 : loss : 0.317586, loss_ce: 0.066288
[10:12:06.828] iteration 580 : loss : 0.362099, loss_ce: 0.114516
[10:12:07.166] iteration 581 : loss : 0.335254, loss_ce: 0.084879
[10:12:07.479] iteration 582 : loss : 0.352406, loss_ce: 0.087734
[10:12:07.790] iteration 583 : loss : 0.346215, loss_ce: 0.118935
[10:12:08.099] iteration 584 : loss : 0.322307, loss_ce: 0.059009
[10:12:08.411] iteration 585 : loss : 0.338104, loss_ce: 0.094800
[10:12:08.721] iteration 586 : loss : 0.483846, loss_ce: 0.077340
[10:12:09.033] iteration 587 : loss : 0.400480, loss_ce: 0.167089
[10:12:09.344] iteration 588 : loss : 0.359170, loss_ce: 0.115315
[10:12:09.657] iteration 589 : loss : 0.327931, loss_ce: 0.082372
[10:12:09.967] iteration 590 : loss : 0.350643, loss_ce: 0.074689
[10:12:10.280] iteration 591 : loss : 0.373257, loss_ce: 0.103540
[10:12:10.592] iteration 592 : loss : 0.368028, loss_ce: 0.059693
[10:12:10.910] iteration 593 : loss : 0.346771, loss_ce: 0.087999
[10:12:11.225] iteration 594 : loss : 0.310630, loss_ce: 0.045730
[10:12:11.535] iteration 595 : loss : 0.435918, loss_ce: 0.236170
[10:12:11.846] iteration 596 : loss : 0.321260, loss_ce: 0.063781
[10:12:12.156] iteration 597 : loss : 0.374909, loss_ce: 0.146781
[10:12:12.468] iteration 598 : loss : 0.396146, loss_ce: 0.161735
[10:12:12.781] iteration 599 : loss : 0.348193, loss_ce: 0.095102
[10:12:13.093] iteration 600 : loss : 0.386508, loss_ce: 0.145660
[10:12:13.452] iteration 601 : loss : 0.356877, loss_ce: 0.150770
[10:12:13.763] iteration 602 : loss : 0.342396, loss_ce: 0.128653
[10:12:14.073] iteration 603 : loss : 0.405571, loss_ce: 0.142597
[10:12:14.384] iteration 604 : loss : 0.409439, loss_ce: 0.140105
[10:12:14.695] iteration 605 : loss : 0.371660, loss_ce: 0.139855
[10:12:15.008] iteration 606 : loss : 0.341054, loss_ce: 0.099274
[10:12:15.320] iteration 607 : loss : 0.381271, loss_ce: 0.100069
[10:12:15.630] iteration 608 : loss : 0.318193, loss_ce: 0.090556
[10:12:15.941] iteration 609 : loss : 0.307628, loss_ce: 0.060534
[10:12:16.253] iteration 610 : loss : 0.437828, loss_ce: 0.065307
[10:12:16.565] iteration 611 : loss : 0.354242, loss_ce: 0.094914
[10:12:16.877] iteration 612 : loss : 0.341081, loss_ce: 0.065824
[10:12:17.190] iteration 613 : loss : 0.379647, loss_ce: 0.107108
[10:12:17.501] iteration 614 : loss : 0.366787, loss_ce: 0.123444
[10:12:17.813] iteration 615 : loss : 0.405553, loss_ce: 0.072920
[10:12:18.125] iteration 616 : loss : 0.328955, loss_ce: 0.098355
[10:12:18.437] iteration 617 : loss : 0.375823, loss_ce: 0.091837
[10:12:18.750] iteration 618 : loss : 0.341963, loss_ce: 0.119247
[10:12:19.060] iteration 619 : loss : 0.413883, loss_ce: 0.143658
[10:12:19.370] iteration 620 : loss : 0.310717, loss_ce: 0.091751
[10:12:19.704] iteration 621 : loss : 0.352909, loss_ce: 0.128419
[10:12:20.014] iteration 622 : loss : 0.322846, loss_ce: 0.100459
[10:12:20.326] iteration 623 : loss : 0.385763, loss_ce: 0.105710
[10:12:20.641] iteration 624 : loss : 0.307869, loss_ce: 0.103665
[10:12:20.950] iteration 625 : loss : 0.366512, loss_ce: 0.141114
[10:12:21.262] iteration 626 : loss : 0.319353, loss_ce: 0.091350
[10:12:21.573] iteration 627 : loss : 0.482601, loss_ce: 0.140505
[10:12:21.884] iteration 628 : loss : 0.369972, loss_ce: 0.110021
[10:12:22.199] iteration 629 : loss : 0.322866, loss_ce: 0.106124
[10:12:22.512] iteration 630 : loss : 0.372531, loss_ce: 0.087265
[10:12:22.824] iteration 631 : loss : 0.323427, loss_ce: 0.090304
[10:12:23.138] iteration 632 : loss : 0.328776, loss_ce: 0.060571
[10:12:23.450] iteration 633 : loss : 0.322340, loss_ce: 0.092267
[10:12:23.760] iteration 634 : loss : 0.330831, loss_ce: 0.087270
[10:12:24.072] iteration 635 : loss : 0.317440, loss_ce: 0.057008
[10:12:24.382] iteration 636 : loss : 0.360823, loss_ce: 0.083032
[10:12:24.691] iteration 637 : loss : 0.373364, loss_ce: 0.038897
[10:12:25.004] iteration 638 : loss : 0.343625, loss_ce: 0.061778
[10:12:25.316] iteration 639 : loss : 0.365272, loss_ce: 0.092809
[10:12:25.631] iteration 640 : loss : 0.331930, loss_ce: 0.043234
[10:12:25.975] iteration 641 : loss : 0.305378, loss_ce: 0.060624
[10:12:26.288] iteration 642 : loss : 0.322356, loss_ce: 0.083042
[10:12:26.597] iteration 643 : loss : 0.310922, loss_ce: 0.070371
[10:12:26.907] iteration 644 : loss : 0.289637, loss_ce: 0.072642
[10:12:27.218] iteration 645 : loss : 0.316570, loss_ce: 0.048372
[10:12:27.531] iteration 646 : loss : 0.316808, loss_ce: 0.076069
[10:12:27.843] iteration 647 : loss : 0.351262, loss_ce: 0.026112
[10:12:28.155] iteration 648 : loss : 0.301756, loss_ce: 0.067717
[10:12:28.465] iteration 649 : loss : 0.411701, loss_ce: 0.182976
[10:12:28.779] iteration 650 : loss : 0.320771, loss_ce: 0.077261
[10:12:29.091] iteration 651 : loss : 0.305858, loss_ce: 0.067221
[10:12:29.404] iteration 652 : loss : 0.345908, loss_ce: 0.077925
[10:12:29.717] iteration 653 : loss : 0.317594, loss_ce: 0.063160
[10:12:30.031] iteration 654 : loss : 0.403074, loss_ce: 0.123865
[10:12:30.342] iteration 655 : loss : 0.350759, loss_ce: 0.091289
[10:12:30.654] iteration 656 : loss : 0.449289, loss_ce: 0.061120
[10:12:30.969] iteration 657 : loss : 0.382035, loss_ce: 0.167051
[10:12:31.281] iteration 658 : loss : 0.400300, loss_ce: 0.069630
[10:12:31.592] iteration 659 : loss : 0.316437, loss_ce: 0.095393
[10:12:31.903] iteration 660 : loss : 0.344684, loss_ce: 0.115538
[10:12:32.236] iteration 661 : loss : 0.337442, loss_ce: 0.136683
[10:12:32.551] iteration 662 : loss : 0.336758, loss_ce: 0.078402
[10:12:32.865] iteration 663 : loss : 0.363398, loss_ce: 0.136076
[10:12:33.178] iteration 664 : loss : 0.314371, loss_ce: 0.086670
[10:12:33.494] iteration 665 : loss : 0.323627, loss_ce: 0.119913
[10:12:33.805] iteration 666 : loss : 0.352533, loss_ce: 0.036443
[10:12:34.116] iteration 667 : loss : 0.434860, loss_ce: 0.046392
[10:12:34.426] iteration 668 : loss : 0.376997, loss_ce: 0.043571
[10:12:34.739] iteration 669 : loss : 0.378414, loss_ce: 0.168142
[10:12:35.049] iteration 670 : loss : 0.359712, loss_ce: 0.148702
[10:12:35.361] iteration 671 : loss : 0.323680, loss_ce: 0.081879
[10:12:35.673] iteration 672 : loss : 0.365503, loss_ce: 0.107671
[10:12:35.983] iteration 673 : loss : 0.325048, loss_ce: 0.101503
[10:12:36.296] iteration 674 : loss : 0.327277, loss_ce: 0.117311
[10:12:36.610] iteration 675 : loss : 0.299400, loss_ce: 0.052964
[10:12:36.923] iteration 676 : loss : 0.363116, loss_ce: 0.140137
[10:12:37.239] iteration 677 : loss : 0.334229, loss_ce: 0.099993
[10:12:37.551] iteration 678 : loss : 0.359209, loss_ce: 0.068111
[10:12:37.862] iteration 679 : loss : 0.311508, loss_ce: 0.044224
[10:12:38.173] iteration 680 : loss : 0.366132, loss_ce: 0.126487
[10:12:38.511] iteration 681 : loss : 0.296675, loss_ce: 0.055923
[10:12:38.825] iteration 682 : loss : 0.315547, loss_ce: 0.039775
[10:12:39.140] iteration 683 : loss : 0.324615, loss_ce: 0.097141
[10:12:39.452] iteration 684 : loss : 0.348564, loss_ce: 0.105608
[10:12:39.764] iteration 685 : loss : 0.339746, loss_ce: 0.110122
[10:12:40.074] iteration 686 : loss : 0.311501, loss_ce: 0.058785
[10:12:40.388] iteration 687 : loss : 0.299934, loss_ce: 0.109041
[10:12:40.702] iteration 688 : loss : 0.370843, loss_ce: 0.073187
[10:12:41.014] iteration 689 : loss : 0.410146, loss_ce: 0.113027
[10:12:41.326] iteration 690 : loss : 0.435791, loss_ce: 0.058781
[10:12:41.637] iteration 691 : loss : 0.406532, loss_ce: 0.052897
[10:12:41.951] iteration 692 : loss : 0.299121, loss_ce: 0.043140
[10:12:42.265] iteration 693 : loss : 0.336993, loss_ce: 0.073395
[10:12:42.577] iteration 694 : loss : 0.353869, loss_ce: 0.061992
[10:12:42.888] iteration 695 : loss : 0.350293, loss_ce: 0.118444
[10:12:43.199] iteration 696 : loss : 0.327080, loss_ce: 0.036323
[10:12:43.513] iteration 697 : loss : 0.330404, loss_ce: 0.051911
[10:12:43.826] iteration 698 : loss : 0.313573, loss_ce: 0.072648
[10:12:44.138] iteration 699 : loss : 0.335779, loss_ce: 0.061472
[10:12:44.451] iteration 700 : loss : 0.345919, loss_ce: 0.082793
[10:12:44.788] iteration 701 : loss : 0.341609, loss_ce: 0.079977
[10:12:45.098] iteration 702 : loss : 0.329897, loss_ce: 0.077043
[10:12:45.410] iteration 703 : loss : 0.456186, loss_ce: 0.052863
[10:12:45.721] iteration 704 : loss : 0.308607, loss_ce: 0.058555
[10:12:46.033] iteration 705 : loss : 0.393029, loss_ce: 0.169364
[10:12:46.346] iteration 706 : loss : 0.341308, loss_ce: 0.092276
[10:12:46.657] iteration 707 : loss : 0.461999, loss_ce: 0.052124
[10:12:46.967] iteration 708 : loss : 0.379987, loss_ce: 0.151776
[10:12:47.278] iteration 709 : loss : 0.335166, loss_ce: 0.075489
[10:12:47.592] iteration 710 : loss : 0.395271, loss_ce: 0.092897
[10:12:47.905] iteration 711 : loss : 0.391050, loss_ce: 0.061490
[10:12:48.218] iteration 712 : loss : 0.334422, loss_ce: 0.102959
[10:12:48.530] iteration 713 : loss : 0.385743, loss_ce: 0.047582
[10:12:48.846] iteration 714 : loss : 0.314517, loss_ce: 0.080537
[10:12:49.158] iteration 715 : loss : 0.364439, loss_ce: 0.069898
[10:12:49.471] iteration 716 : loss : 0.378553, loss_ce: 0.098565
[10:12:49.782] iteration 717 : loss : 0.375868, loss_ce: 0.097262
[10:12:50.091] iteration 718 : loss : 0.293045, loss_ce: 0.046824
[10:12:50.403] iteration 719 : loss : 0.318344, loss_ce: 0.076486
[10:12:50.716] iteration 720 : loss : 0.368705, loss_ce: 0.088911
[10:12:51.058] iteration 721 : loss : 0.304555, loss_ce: 0.069522
[10:12:51.372] iteration 722 : loss : 0.293024, loss_ce: 0.064755
[10:12:51.684] iteration 723 : loss : 0.357979, loss_ce: 0.093751
[10:12:51.996] iteration 724 : loss : 0.320921, loss_ce: 0.089244
[10:12:52.306] iteration 725 : loss : 0.300691, loss_ce: 0.082191
[10:12:52.617] iteration 726 : loss : 0.405083, loss_ce: 0.102373
[10:12:52.929] iteration 727 : loss : 0.381754, loss_ce: 0.178529
[10:12:53.242] iteration 728 : loss : 0.369400, loss_ce: 0.136275
[10:12:53.555] iteration 729 : loss : 0.336207, loss_ce: 0.120676
[10:12:53.871] iteration 730 : loss : 0.307550, loss_ce: 0.083450
[10:12:54.186] iteration 731 : loss : 0.278212, loss_ce: 0.052982
[10:12:54.499] iteration 732 : loss : 0.385977, loss_ce: 0.059520
[10:12:54.812] iteration 733 : loss : 0.285153, loss_ce: 0.079383
[10:12:55.124] iteration 734 : loss : 0.369041, loss_ce: 0.092965
[10:12:55.437] iteration 735 : loss : 0.337997, loss_ce: 0.116623
[10:12:55.747] iteration 736 : loss : 0.309299, loss_ce: 0.049739
[10:12:56.060] iteration 737 : loss : 0.319935, loss_ce: 0.080786
[10:12:56.371] iteration 738 : loss : 0.291654, loss_ce: 0.054986
[10:12:56.683] iteration 739 : loss : 0.362285, loss_ce: 0.049006
[10:12:56.997] iteration 740 : loss : 0.321809, loss_ce: 0.108868
[10:12:57.355] iteration 741 : loss : 0.311845, loss_ce: 0.074195
[10:12:57.667] iteration 742 : loss : 0.413029, loss_ce: 0.030367
[10:12:57.979] iteration 743 : loss : 0.403228, loss_ce: 0.111950
[10:12:58.290] iteration 744 : loss : 0.386181, loss_ce: 0.079317
[10:12:58.603] iteration 745 : loss : 0.314879, loss_ce: 0.063313
[10:12:58.914] iteration 746 : loss : 0.395932, loss_ce: 0.044160
[10:12:59.227] iteration 747 : loss : 0.338993, loss_ce: 0.116064
[10:12:59.540] iteration 748 : loss : 0.321878, loss_ce: 0.086626
[10:12:59.852] iteration 749 : loss : 0.337342, loss_ce: 0.131571
[10:13:00.164] iteration 750 : loss : 0.388085, loss_ce: 0.167603
[10:13:00.473] iteration 751 : loss : 0.359198, loss_ce: 0.125700
[10:13:00.785] iteration 752 : loss : 0.377385, loss_ce: 0.077684
[10:13:01.097] iteration 753 : loss : 0.301051, loss_ce: 0.108248
[10:13:01.410] iteration 754 : loss : 0.310498, loss_ce: 0.079544
[10:13:01.720] iteration 755 : loss : 0.394417, loss_ce: 0.082980
[10:13:02.034] iteration 756 : loss : 0.318520, loss_ce: 0.080987
[10:13:02.346] iteration 757 : loss : 0.360748, loss_ce: 0.116643
[10:13:02.659] iteration 758 : loss : 0.326342, loss_ce: 0.050434
[10:13:02.971] iteration 759 : loss : 0.310734, loss_ce: 0.080521
[10:13:03.285] iteration 760 : loss : 0.304345, loss_ce: 0.081043
[10:13:03.623] iteration 761 : loss : 0.318082, loss_ce: 0.094653
[10:13:03.932] iteration 762 : loss : 0.436804, loss_ce: 0.032212
[10:13:04.244] iteration 763 : loss : 0.394970, loss_ce: 0.126199
[10:13:04.557] iteration 764 : loss : 0.322355, loss_ce: 0.096603
